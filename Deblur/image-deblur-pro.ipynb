{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":579020,"sourceType":"datasetVersion","datasetId":270005},{"sourceId":12036554,"sourceType":"datasetVersion","datasetId":7573812}],"dockerImageVersionId":30209,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport random\nimport cv2\nimport os\nimport tensorflow as tf\nfrom tqdm import tqdm","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T13:59:55.090143Z","iopub.execute_input":"2025-06-02T13:59:55.090969Z","iopub.status.idle":"2025-06-02T13:59:55.098218Z","shell.execute_reply.started":"2025-06-02T13:59:55.090936Z","shell.execute_reply":"2025-06-02T13:59:55.097335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"good_frames = '../input/blur-dataset/sharp'\nbad_frames = '../input/blur-dataset/defocused_blurred'","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T13:59:55.099918Z","iopub.execute_input":"2025-06-02T13:59:55.100285Z","iopub.status.idle":"2025-06-02T13:59:55.117707Z","shell.execute_reply.started":"2025-06-02T13:59:55.100259Z","shell.execute_reply":"2025-06-02T13:59:55.116912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_frames = []\nfor file in tqdm(sorted(os.listdir(good_frames))):\n    if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n        image = tf.keras.preprocessing.image.load_img(good_frames + '/' + file, target_size=(128,128))\n        image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n        clean_frames.append(image)\n\nclean_frames = np.array(clean_frames)\nblurry_frames = []\nfor file in tqdm(sorted(os.listdir(bad_frames))):\n    if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n        image = tf.keras.preprocessing.image.load_img(bad_frames + '/' + file, target_size=(128,128))\n        image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n        blurry_frames.append(image)\n\nblurry_frames = np.array(blurry_frames)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T13:59:55.11862Z","iopub.execute_input":"2025-06-02T13:59:55.118863Z","iopub.status.idle":"2025-06-02T14:00:26.263176Z","shell.execute_reply.started":"2025-06-02T13:59:55.118839Z","shell.execute_reply":"2025-06-02T14:00:26.262276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.layers import Dense, Input\nfrom keras.layers import Conv2D, Flatten\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.utils.vis_utils import plot_model\nfrom keras import backend as K\n\nseed = 21\nrandom.seed = seed\nnp.random.seed = seed","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:26.264589Z","iopub.execute_input":"2025-06-02T14:00:26.26497Z","iopub.status.idle":"2025-06-02T14:00:26.271525Z","shell.execute_reply.started":"2025-06-02T14:00:26.264931Z","shell.execute_reply":"2025-06-02T14:00:26.2706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = clean_frames;\ny = blurry_frames;\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:26.273555Z","iopub.execute_input":"2025-06-02T14:00:26.273813Z","iopub.status.idle":"2025-06-02T14:00:26.771326Z","shell.execute_reply.started":"2025-06-02T14:00:26.273789Z","shell.execute_reply":"2025-06-02T14:00:26.770545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(x_train[0].shape)\nprint(y_train[0].shape)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:26.772519Z","iopub.execute_input":"2025-06-02T14:00:26.772862Z","iopub.status.idle":"2025-06-02T14:00:26.777738Z","shell.execute_reply.started":"2025-06-02T14:00:26.772834Z","shell.execute_reply":"2025-06-02T14:00:26.776777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r = random.randint(0, len(clean_frames)-1)\nprint(r)\nfig = plt.figure()\nfig.subplots_adjust(hspace=0.1, wspace=0.2)\nax = fig.add_subplot(1, 2, 1)\nax.imshow(clean_frames[r])\nax = fig.add_subplot(1, 2, 2)\nax.imshow(blurry_frames[r])","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:26.779087Z","iopub.execute_input":"2025-06-02T14:00:26.779439Z","iopub.status.idle":"2025-06-02T14:00:27.085059Z","shell.execute_reply.started":"2025-06-02T14:00:26.779405Z","shell.execute_reply":"2025-06-02T14:00:27.084197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Network Parameters\ninput_shape = (128, 128, 3)\nbatch_size = 32\nkernel_size = 3\nlatent_dim = 256\n\n# Encoder/Decoder number of CNN layers and filters per layer\nlayer_filters = [64, 128, 256]","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:27.086331Z","iopub.execute_input":"2025-06-02T14:00:27.087049Z","iopub.status.idle":"2025-06-02T14:00:27.091916Z","shell.execute_reply.started":"2025-06-02T14:00:27.086993Z","shell.execute_reply":"2025-06-02T14:00:27.09117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = Input(shape = input_shape, name = 'encoder_input')\nx = inputs","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:27.0933Z","iopub.execute_input":"2025-06-02T14:00:27.093878Z","iopub.status.idle":"2025-06-02T14:00:27.13834Z","shell.execute_reply.started":"2025-06-02T14:00:27.093843Z","shell.execute_reply":"2025-06-02T14:00:27.137679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for filters in layer_filters:\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               strides=2,\n               activation='relu',\n               padding='same')(x)\nshape = K.int_shape(x)\nx = Flatten()(x)\nlatent = Dense(latent_dim, name='latent_vector')(x)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:27.139361Z","iopub.execute_input":"2025-06-02T14:00:27.139622Z","iopub.status.idle":"2025-06-02T14:00:31.208566Z","shell.execute_reply.started":"2025-06-02T14:00:27.139598Z","shell.execute_reply":"2025-06-02T14:00:31.207784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = Model(inputs, latent, name='encoder')\nencoder.summary()","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:31.210095Z","iopub.execute_input":"2025-06-02T14:00:31.210447Z","iopub.status.idle":"2025-06-02T14:00:31.219893Z","shell.execute_reply.started":"2025-06-02T14:00:31.210413Z","shell.execute_reply":"2025-06-02T14:00:31.218917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\nx = Dense(shape[1]*shape[2]*shape[3])(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\nfor filters in layer_filters[::-1]:\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        strides=2,\n                        activation='relu',\n                        padding='same')(x)\n\noutputs = Conv2DTranspose(filters=3,\n                          kernel_size=kernel_size,\n                          activation='sigmoid',\n                          padding='same',\n                          name='decoder_output')(x)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:31.220993Z","iopub.execute_input":"2025-06-02T14:00:31.221287Z","iopub.status.idle":"2025-06-02T14:00:31.288205Z","shell.execute_reply.started":"2025-06-02T14:00:31.221261Z","shell.execute_reply":"2025-06-02T14:00:31.287335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"decoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:31.289263Z","iopub.execute_input":"2025-06-02T14:00:31.289498Z","iopub.status.idle":"2025-06-02T14:00:31.298125Z","shell.execute_reply.started":"2025-06-02T14:00:31.289475Z","shell.execute_reply":"2025-06-02T14:00:31.297155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\ndef build_unet_autoencoder(input_shape=(128, 128, 3)):\n    inputs = Input(shape=input_shape)\n\n    # ----- Encoder -----\n    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    p1 = MaxPooling2D((2, 2))(c1)\n\n    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n    p2 = MaxPooling2D((2, 2))(c2)\n\n    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n    p3 = MaxPooling2D((2, 2))(c3)\n\n    # Bottleneck\n    bottleneck = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n\n    # ----- Decoder -----\n    u3 = UpSampling2D((2, 2))(bottleneck)\n    concat3 = Concatenate()([u3, c3])\n    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat3)\n\n    u2 = UpSampling2D((2, 2))(c4)\n    concat2 = Concatenate()([u2, c2])\n    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat2)\n\n    u1 = UpSampling2D((2, 2))(c5)\n    concat1 = Concatenate()([u1, c1])\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat1)\n\n    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c6)\n\n    model = Model(inputs=inputs, outputs=outputs, name=\"unet_autoencoder\")\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\nautoencoder = build_unet_autoencoder(input_shape=(128, 128, 3))\nautoencoder.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"autoencoder.compile(loss='mse', optimizer='adam',metrics=[\"acc\"])","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:31.368056Z","iopub.execute_input":"2025-06-02T14:00:31.36866Z","iopub.status.idle":"2025-06-02T14:00:31.381898Z","shell.execute_reply.started":"2025-06-02T14:00:31.368624Z","shell.execute_reply":"2025-06-02T14:00:31.381063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               verbose=1,\n                               min_lr=0.5e-6)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:31.383075Z","iopub.execute_input":"2025-06-02T14:00:31.383398Z","iopub.status.idle":"2025-06-02T14:00:31.388916Z","shell.execute_reply.started":"2025-06-02T14:00:31.383361Z","shell.execute_reply":"2025-06-02T14:00:31.388066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"callbacks = [lr_reducer]\nhistory = autoencoder.fit(blurry_frames,\n                      clean_frames,\n                      validation_data=(blurry_frames, clean_frames),\n                      epochs=100,\n                      batch_size=batch_size,\n                      callbacks=callbacks)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:00:31.389952Z","iopub.execute_input":"2025-06-02T14:00:31.390255Z","iopub.status.idle":"2025-06-02T14:01:54.706397Z","shell.execute_reply.started":"2025-06-02T14:00:31.390231Z","shell.execute_reply":"2025-06-02T14:01:54.7056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n       Input                        Ground Truth                  Predicted Value\")\nfor i in range(3):\n    \n    r = random.randint(0, len(clean_frames)-1)\n\n    x, y = blurry_frames[r],clean_frames[r]\n    x_inp=x.reshape(1,128,128,3)\n    result = autoencoder.predict(x_inp)\n    result = result.reshape(128,128,3)\n\n    fig = plt.figure(figsize=(12,10))\n    fig.subplots_adjust(hspace=0.1, wspace=0.2)\n\n    ax = fig.add_subplot(1, 3, 1)\n    ax.imshow(x)\n\n    ax = fig.add_subplot(1, 3, 2)\n    ax.imshow(y)\n\n    ax = fig.add_subplot(1, 3, 3)\n    plt.imshow(result)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:01:54.707959Z","iopub.execute_input":"2025-06-02T14:01:54.70864Z","iopub.status.idle":"2025-06-02T14:01:56.078041Z","shell.execute_reply.started":"2025-06-02T14:01:54.708597Z","shell.execute_reply":"2025-06-02T14:01:56.07707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train', 'Test'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0, 101, 25))\nplt.show()","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:01:56.083467Z","iopub.execute_input":"2025-06-02T14:01:56.083771Z","iopub.status.idle":"2025-06-02T14:01:56.233069Z","shell.execute_reply.started":"2025-06-02T14:01:56.083743Z","shell.execute_reply":"2025-06-02T14:01:56.232081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.legend(['Train', 'Test'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xticks(np.arange(0, 101, 25))\nplt.show()","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-02T14:01:56.234499Z","iopub.execute_input":"2025-06-02T14:01:56.234859Z","iopub.status.idle":"2025-06-02T14:01:56.37589Z","shell.execute_reply.started":"2025-06-02T14:01:56.234821Z","shell.execute_reply":"2025-06-02T14:01:56.374907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"autoencoder.save('deblur_autoencoder_model.keras')\n# autoencoder.save('deblur_autoencoder_model.h5', save_format='h5')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T14:21:28.099882Z","iopub.execute_input":"2025-06-02T14:21:28.100737Z","iopub.status.idle":"2025-06-02T14:21:28.529149Z","shell.execute_reply.started":"2025-06-02T14:21:28.100703Z","shell.execute_reply":"2025-06-02T14:21:28.528091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\n\n# 載入儲存好的模型\nmodel_path = '/kaggle/working/deblur_autoencoder_model.keras'\nimport h5py  # 確保 h5py 已安裝\nautoencoder = keras.models.load_model(model_path, compile=False)\n\n\n# 預處理圖片函式\ndef preprocess_image(image_path, target_size=(128, 128)):\n    image = cv2.imread(image_path)\n    if image is None:\n        raise FileNotFoundError(f\"Image not found: {image_path}\")\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, target_size)\n    image = image.astype('float32') / 255.0\n    return np.expand_dims(image, axis=0), image\n\n# 處理輸入圖片\ninput_path = '/kaggle/input/test-input/testjpg.jpg'\ninput_image, input_display = preprocess_image(input_path)\n\n# 預測\npredicted_image = autoencoder.predict(input_image)[0]\npredicted_image = np.clip(predicted_image, 0, 1)\n\n# 顯示結果\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Input Blurry Image\")\nplt.imshow(input_display)\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nplt.title(\"Predicted Deblurred Image\")\nplt.imshow(predicted_image)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T14:20:59.927609Z","iopub.execute_input":"2025-06-02T14:20:59.927953Z","iopub.status.idle":"2025-06-02T14:21:00.99852Z","shell.execute_reply.started":"2025-06-02T14:20:59.927923Z","shell.execute_reply":"2025-06-02T14:21:00.997605Z"}},"outputs":[],"execution_count":null}]}